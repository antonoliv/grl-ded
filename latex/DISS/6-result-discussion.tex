\chapter{Result Discussion}

In this chapter, the obtained results are thoroughly analysed and discussed. The performed experiments can be subdivided into 6 categories: Curtail Lower Limit (section \ref{sec:curtailment-lower-limit}), Limit Infeasible Curtailment Actions \ref{sec:limit-infeasible}, Reward Tests\ref{sec:rewards}, \acp{GNN} Hyperparameter Tuning, \ac{GNN} Implementation Comparison \ref{sec:gnn-comparison} and Scability Tests \ref{sec:gnn-comparison}.

\begin{comment}
	* Best SAC and GNN parameters
	* Environment Parameters
	* Explain that SAC was used for most experiments as a baseline
	* Explain the non-reproducability of experiements (https://github.com/pytorch/pytorch/issues/50469)
\end{comment}

\begin{table}
	\begin{tabular}{|l | l|}
		\hline
		Learning Rate & 1e-4 \\
		\hline
		Gamma & 0.85 \\
		\hline
		Entropy Coefficient & 'auto' \\
		\hline
		Gradient Steps & 1 \\
		\hline
		Buffer Size & 1e6 \\
		\hline
		Batch Size & 256 \\
		\hline
		Tau & 0.001 \\
		\hline
		Target Update Interval & 1 \\
		\hline
		Training Frequency & 1 \\
		\hline
		Target Entropy & 'auto' \\
		\hline 
		Optimizer & Adam \\
		\hline
		Activation Function & ReLU \\
		\hline
		Number of Units per Hidden Layer & 128 \\
		\hline
		Number of Hidden Layers & 6 \\
		\hline
		\end{tabular}
		\caption{Soft Actor-Critic Parameters}
\end{table}

\begin{table}
	\begin{tabular}{|l|l|}
		\hline
		Input Channels & 6 \\
		\hline
		Hidden Channels & 18 \\
		\hline
		Number of Layers & 2 \\
		\hline
		Output Channels & 6 \\
		\hline
		Dropout Rate & 0.1 \\
		\hline
		Activation Function & ReLu \\
		 \hline
		Aggregation Function & 'sum' \\
		\hline
		act\_first & True \\
		\hline
		Flow & Source to Target \\
		\hline
		Node Dimension & -2 \\
		\hline 
		Decomposed Layers & -1 \\
		\hline
		Improved & False \\
		\hline
		Cached & False \\
		\hline
		Normalize & True \\
		\hline
		Bias & True \\		
		\hline
	\end{tabular}
	\caption{\ac{GCN} Parameters}
\end{table}

\section{Limit Infeasible Curtailment Actions} \label{sec:limit-infeasible}

\section{Curtailment Lower Limit} \label{sec:curtailment-lower-limit}

The initial exploratory experiments and posterior analysis of training performance showed significant instability and lack of convergence of \ac{DRL} models. This is aggravated by the inclusion of curtailment actions in the action space, which in turn introduced additional complexity to the decision process and severely affected the model's survivability. 
\par
Considering the secondary goal of maximization of generated renewable energy, the idealization of a lower bound to restrict the curtailment action space became a potential solution to aid in the model's convergence. Additionally, two methods of 

\begin{comment}
	Graph:
	- No limit
	- Fixed Limit
	- Linear Limit
	- Sqrt Limit
\end{comment}

\begin{comment}
	Validation Table
	Graph:
	- No limit
	- Fixed Limit
	- Linear Limit
	- Sqrt Limit
\end{comment}

Results showed in graph GRAPH proved that the introduced curtailment lower bounds considerably increased the models training performance and convergence, with the square root decay method achieving the overall highest average accumulated reward during validation. Introducing a decay in the lower bound limit implies an enhanced overall performance and survivability of the algorithm.

\section{Rewards Tests} \label{sec:rewards}

Several implementations posed as relevant formulas to describe the reward function of the environment, namely three: Economic Reward, \acp{RES} Penalty Factor Reward and \acp{RES} Bonus Reward. The first considered only the saved cost in non-renewable generators operation, while the second and third accounted for \ac{RES} maximization in a penalty and bonus factor, respectively.
\par

Considering the new parameter introduced by both the Penalty and Bonus Factor rewards, $\beta$, the experiments took into account three distinct values: $\{0.2, 0.4, 0.6\}$.


\par
\begin{comment}
	Graph:
	- Economic Reward
	- Penalty Reward
	- Bonus Reward
	
	Graph:
	- 0.2 pen
	- 0.4 pen
	- 0.6 pen
	- 0.2 bonus
	- 0.4 bonus
	- 0.6 bonus
	
	Do result discussion:
	- Penalty with 0.4 factor was the best
\end{comment}

It's critical to take into account that when evaluating and comparing Reward Functions, the average accumulative reward values have different meanings. Furthermore, other crucial metrics such as the survival rate and the average daily operating cost are favoured.
\par
Results revealed that the proposed implementations were superior to the already defined Economic Reward both in survivability and overall performance of the models. The with the best results were observed in the Penalty Factor Reward with $\beta = 0.2$.

\section{\acp{GNN} Hyperparameter Tuning} \label{sec:gnn-hypertune}

As a key area of this research work, the \ac{GNN} component of the proposed algorithm was given a particular focus in what accounts for hyperparameter tuning. Concrete experiments were devised to assess the performance of different parameter combinations, mainly using the GCN-SAC algorithm. \par

The \ac{GNN} aggregation function plays a fundamental role in the architecture of the solution so the tuning process first focused on this parameter. There are five available types of aggregation schemes:
\begin{itemize}
\item \textbf{Sum} - 
\item \textbf{Max} -
\item \textbf{Min} - 
\item \textbf{Mean} - 
\item \textbf{Mul} - 
\end{itemize}

\begin{comment}
	Validation episodes 295
	119 -> 83
\end{comment}
In a first experiment, five models each with the different types of aggregation functions were trained for 5000 episodes. The main parameters and results can be observed in appendix \ref{appendix}, section \ref{appendix:aggr}. The function that obtained the best average accumulative reward during validation was \texttt{max}, achieving around $4\%$ more than the second placed \texttt{sum} function. Furthermore, this model managed to do better than average in most metrics while simultaneously being outperformed in all of them, which shows the balance between the importance of cost saving while considering the maximization of renewable energy. \par

Regarding the number of \ac{GNN} layers, section \ref{appendix:layers} of appendix \ref{appendix} represents the results from the conducted experiment with this scope. This test considered the \texttt{max} aggregation function and a number of \ac{GCN} layers between $[1,6]$. In contrast with the last experiment, the best model which used a 6-layer \ac{GNN} outperformed the second place with a significant difference of $22.4\%$. This results led to the use of these two parameters in the \ac{GCN} model.




\section{GNN Implementation Comparison} \label{sec:gnn-comparison}

\section{Scalability Tests} \label{sec:scalability-tests}

