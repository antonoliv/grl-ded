{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Technolgies\n",
    "\n",
    "## Gymnasium\n",
    "\n",
    "An API standard for reinforcement learning with a diverse collection of reference environments. Gymnasium is a maintained fork of OpenAIâ€™s Gym library.\n",
    "It's a toolkit for developing and comparing different RL algorithms by providing a variety of different prebuilt environments and a consistent API for interacting with such environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# Initizaling environment\n",
    "env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
    "\n",
    "# Get first observation\n",
    "observation, info = env.reset(seed=42)\n",
    "for _ in range(1000):\n",
    "   action = env.action_space.sample()  # this is where you would insert your policy, currently sampling a random action\n",
    "\n",
    "   # Perform action\n",
    "   observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "   \n",
    "\n",
    "   # If environment crashes reset\n",
    "   if terminated or truncated:\n",
    "      observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action and Observation Spaces\n",
    "\n",
    "There are two attributes **env.action_space** and **env.observation_space** that define these two concepts in *Gymnasium*.\n",
    "\n",
    "They can be of different types:\n",
    "* **Box** - n-dimensional continuous space bounded by upper and lower limits that define the valid values\n",
    "* **Discrete** - discrete space where {0, 1, ..., n - 1} are the possible values, can be shifted via optional argument\n",
    "* **Dict** - dictionary of simple spaces\n",
    "* **Tuple** - represents a tuple of simple spaces\n",
    "* **MultiBinary** - n-shape binary space, n can be a number or a list of numbers\n",
    "* **MultiDiscrete** - series of **Discrete** action spaces with a different number of actions in each element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the environment via wrappers\n",
    "\n",
    "Convenient way to modify existing environments without altering the underlying code\n",
    "\n",
    "Common wrappers:\n",
    "* **TimeLimit**: Issue a truncated signal if a maximum number of timesteps has been exceeded (or the base environment has issued a truncated signal).\n",
    "\n",
    "* **ClipAction**: Clip the action such that it lies in the action space (of type Box).\n",
    "\n",
    "* **RescaleAction**: Rescale actions to lie in a specified interval\n",
    "\n",
    "* **TimeAwareObservation**: Add information about the index of timestep to observation. In some cases helpful to ensure that transitions are Markov.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
